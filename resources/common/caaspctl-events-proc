#!/usr/bin/env python
#
# A script for parsing Salt `returns` as:
#
#   * a list of JSON objects, with one object per line, or
#   * as a JSON list of objects
#
# and
#
#   * filtering by
#     * orchestration
#     * last orchestration
#     * failed orchestrations
#     * JID
#     * ...
#   * pretty-printing a bug JSON output
#   * printing a CSV wiwth all the
#
#
# Usage:
#
# A) For using in the Admin node:
#
#    1) get the list of returns in the database with something like
#
#         mysql -uroot "-p<PASSWORD>" -B \
#             -e 'SELECT data FROM salt_events ORDER BY alter_time;' <DATABASE>
#
#       replacing the PASSWORD and DATABASE and redirecting the output to a file.
#       This will dump one JSON object per line.
#
#    2) use this script with the `--infile` argument pointing to the file
#       previously obtained.
#
# B) for using the the velum-salt-events file:
#
#    1) parse the file with
#
#       cat velum-salt-events.yml |  tail -n +4 | caaspctl-events-proc --infile-yaml <ARGS>
#

import argparse
import json
import logging
import random
import re
import sys
from datetime import datetime, timedelta

import yaml

log = logging.getLogger(__name__)

# fields exported in CSV files
CSV_FIELDS = ['orch', 'jid', 'node', 'start', 'end', 'stage', 'name', 'result']


parser = argparse.ArgumentParser()
parser.add_argument('--in',
                    dest='infile',
                    nargs='?',
                    type=argparse.FileType('r'),
                    default=sys.stdin)
parser.add_argument('--out',
                    dest='outfile',
                    nargs='?',
                    type=argparse.FileType('wb'),
                    default=sys.stdout)
parser.add_argument('--infile-lines',
                    default=False,
                    action='store_true',
                    help='parse the input file as a sequence of lines with JSON data')
parser.add_argument('--infile-yaml',
                    default=False,
                    action='store_true',
                    help='parse the input as a YAML file')
parser.add_argument('--outfile-yaml',
                    default=False,
                    action='store_true',
                    help='pretty-print as YAML')
parser.add_argument('--outfile-csv',
                    dest='outfile_csv',
                    action='store_true',
                    help='get the orchestration events as a CSV')
parser.add_argument('--outfile-plot',
                    dest='outfile_plot',
                    nargs='?',
                    default=None,
                    help='generate a plot for the orchestration (require plotly)')
parser.add_argument('--outfile-csv-sep',
                    dest='outfile_csv_sep',
                    nargs='?',
                    default=',',
                    help='CSV separator')
parser.add_argument('--filter-orch',
                    dest='filter_orch',
                    action='store_true',
                    help='filter IN orchestrations')
parser.add_argument('--filter-state-sls',
                    dest='filter_state_sls',
                    action='store_true',
                    help='filter IN state SLSs')
parser.add_argument('--filter-orch-last',
                    dest='filter_orch_last',
                    action='store_true',
                    help='only show the last orchestrations')
parser.add_argument('--filter-failed',
                    dest='filter_failed',
                    action='store_true',
                    help='filter IN failed events')
parser.add_argument('--filter-jid',
                    dest='filter_jid',
                    nargs='?',
                    metavar='JID',
                    help='filter IN <JID>')
parser.add_argument('--plotly-user',
                    nargs='?',
                    help='plotly user name')
parser.add_argument('--plotly-token',
                    nargs='?',
                    help='plotly token')

args = parser.parse_args()

if args.outfile_plot:
    args.filter_orch_last = True

if args.filter_orch_last:
    args.filter_orch = True

if args.infile_yaml:
    args.infile_lines = False


##############################################################################
# load/save
##############################################################################

def load_in_file(infile):
    '''
    load the JSON file, maybe as a list of JSON lines
    (as we get from mysql) or as a regular JSON file.
    '''
    data_list = []
    if args.infile_lines:
        if args.infile_yaml:
            log.error("cannot load YAML from lines")
            sys.exit(1)

        for line in infile:
            for t in re.finditer(r"\{.*\}", line):
                try:
                    json_line = t.group()
                    json_line = json_line.replace('\\"', r'"')
                    json_line = json_line.replace('//', r'')
                    data_list.append(json.loads(json_line))
                except ValueError, e:
                    print e, " error on ", json_line, " ..."
    else:
        try:
            if args.infile_yaml:
                data_loaded = yaml.load(infile)
            else:
                data_loaded = json.loads(infile.read())
        except ValueError, e:
            log.error("could not load file %s: %s", infile, e)
            sys.exit(1)

        # we must check if the data loaded is list
        # or a single object
        if isinstance(data_loaded, list):
            data_list = data_loaded
        else:
            data_list.append(data_loaded)

    return data_list


def save_orch_plot(orch_lines):
    if orch_lines:
        import plotly.plotly as py
        import plotly.figure_factory as ff

        if args.plotly_user:
            py.sign_in(args.plotly_user, args.plotly_token)

        def randcolor():
            return random.randrange(0, 256)

        # detect all the possible orch stages, and assign to each one a color
        colors = {}
        for orch_line in orch_lines:
            if orch_line['name'] not in colors:
                colors[orch_line['name']] = 'rgb({},{},{})'.format(
                    randcolor(), randcolor(), randcolor())

        actions = []
        for orch_line in orch_lines:
            action_item = {'Task': orch_line['node'],
                           'Node': orch_line['name'],
                           'Start': orch_line['start'],
                           'Finish': orch_line['end'],
                           'Resource': orch_line['result']}
            actions.append(action_item)

        fig = ff.create_gantt(actions,
                              colors=colors,
                              index_col='Node',
                              title='Orchestration',
                              group_tasks=True)
        py.plot(fig,
                filename=args.outfile_plot,
                world_readable=True)


def save_orch_csv(orch_lines):
    if orch_lines:
        import csv
        writer = csv.DictWriter(args.outfile,
                                delimiter=args.outfile_csv_sep,
                                fieldnames=CSV_FIELDS)

        writer.writeheader()
        for line in orch_lines:
            writer.writerow(line)

##############################################################################
# parsing
##############################################################################


def parse_orch_by_node(data_list):
    '''
    Return a list of dictionaries, one per node, with
    the list of steps in the orchestration

    res = {
      'node1': [
        {
            'name': 'etc_hosts_setup',
            'start': '07:51:35.348935',
            'end': '07:51:37.658765',
            'result': 'true',
        },
      ]
    }
    '''
    res = {}

    def add_for_node(node, **kwargs):
        if not node in res:
            res[node] = []

        action_dict = {key: 'unknown' for key in CSV_FIELDS}
        action_dict.update({
            'node': node,
            'start': datetime.now(),
            'end': datetime.now(),
        })
        action_dict.update(kwargs)
        res[node].append(action_dict)

    def get_name_for_action(action_name):
        comps = action_name.split('|')
        name = '{}{}'.format(comps[0], comps[1])

        # cleanup some nasty chars
        name = name.replace('_\n', '\n')
        name = name.replace('_-', ':')
        return name

    def get_times_from_action(action):
        '''
        Parse times like:

        "duration": 10721.716,
        "start_time": "17:12:22.273274"
        '''
        start_time = action['start_time']
        duration = action['duration']

        start_time = datetime.strptime(start_time, '%H:%M:%S.%f')
        end_time = start_time + timedelta(seconds=float(duration))
        return start_time, end_time

    def parse_action(name, action, **kwargs):
        if isinstance(action, dict):
            try:
                name = get_name_for_action(action_name)
                result = action['result']
            except KeyError as e:
                continue

            try:
                start_time, end_time = get_times_from_action(action)
            except KeyError as e:
                log.debug('cannot parse times in %s', str(action))
                continue

            action_dict = {
                'stage': stage,
                'name': name,
                'start': start_time,
                'end': end_time,
                'jid': jid,
                'result': result,
            }
            action_dict.update(kwargs)
            add_for_node(node, **action_dict)

    def parse_actions(node, actions, **kwargs):
        '''
        Parse a list of actions like:

            "caasp_cri_|-haproxy-restart_|-haproxy_|-stop_container_and_wait": {
                "__id__": "haproxy-restart",
                "__run_num__": 41,
                "changes": {},
                "comment": "kube-system.haproxy successfully restarted",
                "duration": 10721.716,
                "name": "haproxy",
                "namespace": "kube-system",
                "result": true,
                "start_time": "17:12:22.273274"
            },
        '''
        for action_name, action in actions.items():
            if isinstance(action, dict):
                try:
                    name = get_name_for_action(action_name)
                    result = action['result']
                except KeyError as e:
                    continue

                try:
                    start_time, end_time = get_times_from_action(action)
                except KeyError as e:
                    log.debug('cannot parse times in %s', str(action))
                    continue

                action_dict = {
                    'stage': stage,
                    'name': name,
                    'start': start_time,
                    'end': end_time,
                    'jid': jid,
                    'result': result,
                }
                action_dict.update(kwargs)
                add_for_node(node, **action_dict)

    for data in data_list:
        if 'return' not in data:
            # we are only interested in 'returns'
            continue

        jid = data['jid']
        fun = data['fun']

        if fun in ['state.highstate', 'state.sls']:
            node = data['id']
            actions = data['return']
            retcode = int(data['retcode'])
            stage = 'highstate' if fun == 'state.highstate' else 'sls'

            if retcode != 0:
                # this is an error
                print actions
                msg = 'ERROR: ' + actions[0][:20] + '...'
                add_for_node(node, stage='highstate', name=msg, jid=jid, result=False)
            else:
                parse_actions(node, {node: actions.values()}, stage=stage, jid=jid)

        elif fun == "runner.state.orchestrate":
            orch_name = data['fun_args'][0]
            return_data = data['return']['data']
            steps = return_data[return_data.keys()[0]]
            for step in steps.values():
                stage = step.get('__id__', 'unknown')

                try:
                    step_changes = step['changes']
                except (KeyError, TypeError) as e:
                    print ">>>>", e, "<<<<<: ", step
                    continue

                if isinstance(step_changes, bool):
                    add_for_node("", stage=stage, orch=orch_name,
                                 name=step['name'], jid=jid,
                                 result=step['result'])
                elif isinstance(step_changes, dict):
                    try:
                        orch_steps = step_changes['ret']
                    except (KeyError, TypeError) as e:
                        print ">>>>", e, "<<<<<: ", step
                        add_for_node("", stage=stage, orch=orch_name,
                                     name=step['name'], jid=jid,
                                     result=step['result'])
                    else:
                        for node, actions in orch_steps.items():
                            if not isinstance(actions, dict):
                                continue
                            parse_actions(node, actions, orch=orch_name,
                                          stage=stage, jid=jid)

    res_lst = []
    for node in res:
        for action in res[node]:
            item = {'node': node}
            item.update(action)
            res_lst.append(item)

    res_lst.sort(key=lambda x: x['start'])

    if args.filter_orch_last:
        last_jid = res_lst[-1]['jid']
        res_lst = [x for x in res_lst if x['jid'] == last_jid]

    return res_lst


##############################################################################
# main
##############################################################################

data_list = load_in_file(args.infile)

# filter out the things we are not interested in
filtered_data = []
for data in data_list:

    if args.filter_jid:
        if ("jid" in data) and (data["jid"] != args.filter_jid):
            continue

    if args.filter_failed:
        if ("success" in data) and (data["success"] != "false"):
            continue

    if args.filter_orch:
        if "fun" not in data or (data["fun"] != "runner.state.orchestrate"):
            continue

    if args.filter_state_sls:
        if "fun" not in data or (data["fun"] != "state.sls"):
            continue

    filtered_data.append(data)

#
# output
#
if args.outfile_plot:
    orch_lines = parse_orch_by_node(filtered_data)
    save_orch_plot(orch_lines)
elif args.outfile_csv:
    orch_lines = parse_orch_by_node(filtered_data)
    save_orch_csv(orch_lines)
else:
    if args.outfile_yaml:
        print yaml.dumps(filtered_data, indent=4, sort_keys=True)
    else:
        print json.dumps(filtered_data, indent=4, sort_keys=True)
